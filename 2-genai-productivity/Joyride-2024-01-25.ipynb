{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64c272eb-b3f0-4be4-aa3a-49bf0c57113e",
   "metadata": {},
   "source": [
    "# Demo / Hands-On Session: Gen AI for Internal Productivity Increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8df4ff091bb2617",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-24T07:20:27.620714Z",
     "start_time": "2024-05-24T07:19:52.203605Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib3\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "from src.models import gpt35, gpt4, embedding_model\n",
    "from src.utils import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ayDEMllZEvQd",
   "metadata": {
    "id": "ayDEMllZEvQd"
   },
   "source": [
    "## **Open the Hood - RAG & Semantic Search**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd632359-dee5-4336-958c-d9686c79ee13",
   "metadata": {},
   "source": [
    "<img src=\"data/open-the-hood-wide.jpg\" alt=\"image\" width=\"800\" height=\"auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abcb4d4-33f0-408c-8564-60fc801d184b",
   "metadata": {},
   "source": [
    "For most internal use cases, Large Language Models need access to internal data. The easiest and most popular method to give LLMs access to internal documents is **Retrieval Augmented Generation (RAG)**. \n",
    "\n",
    "The following is a high-level overview of RAG:\n",
    "\n",
    "<img src=\"data/rag.jpg\" alt=\"image\" width=\"600\" height=\"auto\">\n",
    "\n",
    "1. User enters a query that is combined with a pre-configured prompt\n",
    "2. The query is used to search for documents that are relevant to the query\n",
    "3. The *retriever* returns the relevant documents\n",
    "4. Query, prompt and the relevant context are combined and sent to the LLM\n",
    "5. The LLM answers the query by encorporating the provided context\n",
    "\n",
    "The **retrieval** (steps 2 + 3) can be implemented in various ways, as long as it identifies documents that are relevant to the query. Most popular and relatively easy to implement is **semantic search**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdc69d4-5ac6-4fac-947f-fe46cd12ea65",
   "metadata": {},
   "source": [
    "### Semantic Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e7eed3-40db-4170-8f65-f7d67c630c33",
   "metadata": {},
   "source": [
    "A concrete example: Let's say we want to identify passages in our terms and conditions that are relevant for electric vehicles. A simple keyword search is hardly effective because of the different phrases you could use:\n",
    "\n",
    "Search Phrase|Phrase in Terms and Conditions|Match\n",
    "---|---|:---:\n",
    "electrical vehicle|electrical vehicle| <font color=\"green\"> ✔ </font>\n",
    "electrical vehicle|electrical car|❌\n",
    "electrical vehicle|electric car|❌\n",
    "\n",
    "Semantic search & embeddings allow to compare the latent **meaning** of words and phrases:\n",
    "Search Phrase|Phrase in Terms and Conditions|Match\n",
    "---|---|:---:\n",
    "electrical vehicle|electrical vehicle|<font size=\"3\"> ⬤ </font>\n",
    "electrical vehicle|electrical car|<font size=\"4\"> ◕ </font>\n",
    "electrical vehicle|electric car|<font size=\"4\"> ◕ </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MGsaTN29c9cl",
   "metadata": {
    "id": "MGsaTN29c9cl"
   },
   "source": [
    "### Word Embeddings\n",
    "\n",
    "* Embeddings are multidimensional vectors that represent the meaning of words or phrases\n",
    "* Words or phrases with similar meanings have vectors that are close / similar to each other\n",
    "* There are different ways to measure vector similarity. One popular way is cosine similarity: $cos \\varphi = {{\\vec a \\cdot \\vec b} \\over {|\\vec a| \\cdot |\\vec b|}}$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "283adf9b-05be-4985-b253-a31c8fc3e99f",
   "metadata": {},
   "source": [
    "<img src=\"data/cosine-similarity.jpg\" alt=\"image\" width=\"400\" height=\"auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee57b460-d97e-436b-8bf8-43d95bedd12a",
   "metadata": {},
   "source": [
    "Retrieve embeddings from OpenAI embedding models and compute their similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce539de-8d6d-4ff5-99d1-b39ba7d83362",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:29:41.136218Z",
     "start_time": "2024-05-22T15:29:41.122075Z"
    }
   },
   "outputs": [],
   "source": [
    "cosine_similarity(\n",
    "    embedding_model.embed_query(\"electric vehicle\"), \n",
    "    embedding_model.embed_query(\"electric car\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12d97ce-5833-4f2c-9cf2-11fc0571b1a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:29:41.151809Z",
     "start_time": "2024-05-22T15:29:41.139727Z"
    }
   },
   "outputs": [],
   "source": [
    "cosine_similarity(\n",
    "    embedding_model.embed_query(\"electric vehicle\"), \n",
    "    embedding_model.embed_query(\"horse\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05bf838-9b6c-472a-8b03-3872a045a0d7",
   "metadata": {},
   "source": [
    "**TASK**: Adapt the code above to compute similarities of words or longer phrases to get a better feeling for how embeddings relate to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8khnN4kufYY8",
   "metadata": {
    "id": "8khnN4kufYY8"
   },
   "source": [
    "## **Cruising on AXA's freeway**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dd6d6d-982f-497a-91cc-d1e512cd4cfd",
   "metadata": {},
   "source": [
    "<img src=\"data/mustang-cruising-wide.jpg\" alt=\"image\" width=\"800\" height=\"auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sH-LAaMHZvSs",
   "metadata": {
    "id": "sH-LAaMHZvSs"
   },
   "source": [
    "How is this relevant for AXA? One of many ways RAG can be used in an insurance company, is to try to automatically determine whether or not a claim is covered based on the claim description, the individual policy and the general terms and conditions.\n",
    "\n",
    "Prerequisites for our demo:\n",
    "* Access to OpenAIs LLMs und Embedding-Modellen\n",
    "* [General insurance conditions](data/MF-GIC.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9878b1-efa0-4b5a-8ed3-f7840885e57a",
   "metadata": {},
   "source": [
    "Load terms and conditions from a file and compute embeddings for each passage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea622ac-c9e6-4355-b0e5-181e0509a136",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T11:30:02.287002Z",
     "start_time": "2024-05-23T11:30:02.257178Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "insurance_conditions = pd.read_csv(\"data/MF-AVB.csv\", sep=\"@\")\n",
    "insurance_conditions[\"embedding\"] = embedding_model.embed_documents(insurance_conditions[\"Text\"])\n",
    "insurance_conditions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc4f8a1-70c1-4ca5-a1d1-db8bb292ffbb",
   "metadata": {},
   "source": [
    "Function to do a semantic search on terms and conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76454792-d7ef-4f77-82c5-b5a193b8137c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T11:30:02.302389Z",
     "start_time": "2024-05-23T11:30:02.288500Z"
    }
   },
   "outputs": [],
   "source": [
    "def semantic_search(query, df, top_n=10):\n",
    "    \"\"\"Returns the top_n most relevant rows for a given query\"\"\"\n",
    "\n",
    "    # Embed query\n",
    "    query_embedding = embedding_model.embed_query(query)\n",
    "\n",
    "    # Calculate similarity between query and row embedding\n",
    "    df[\"similarity\"] = df[\"embedding\"].apply(\n",
    "        lambda x: cosine_similarity(x, query_embedding)\n",
    "    )\n",
    "\n",
    "    # Return top_n most relevant AVB passages\n",
    "    return df.sort_values(by=\"similarity\", ascending=False).iloc[:top_n][\n",
    "        [\"id\", \"Teil\", \"Titel\", \"Untertitel\", \"Text\", \"similarity\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e3cc19-ff22-4edd-bba2-3047cdc097b5",
   "metadata": {},
   "source": [
    "Execute semantic search for different words and phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea81699-7440-43ca-975a-3168210f5f98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:29:53.473069Z",
     "start_time": "2024-05-22T15:29:52.743643Z"
    }
   },
   "outputs": [],
   "source": [
    "semantic_search(\"Elektroauto\", insurance_conditions, top_n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaacf03-c0d3-4548-90da-706725c0a795",
   "metadata": {},
   "source": [
    "... also works for entire phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacd4592-bbd0-42e3-8dfd-b9c8b188821f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:29:53.889946Z",
     "start_time": "2024-05-22T15:29:53.474222Z"
    }
   },
   "outputs": [],
   "source": [
    "semantic_search(\"Ich hatte einen Zusammenstoss mit einer Wildsau\", insurance_conditions, top_n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098b5127-0b91-4690-9f6f-93aadeb9d013",
   "metadata": {},
   "source": [
    "... also works (to some extent) when using a different language in the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85cd6e0-6864-4765-a546-8aff0582698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_search(\"I crashed into a deer\", insurance_conditions, top_n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9a50da-eead-40fe-b995-c3bcf609fded",
   "metadata": {},
   "source": [
    "### Demo 1: Simple coverage check based on policy and terms & conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce4523f-7da6-42b8-abaa-3b5b29497db2",
   "metadata": {},
   "source": [
    "Load Policy and print extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c84bbb-c7a2-468b-b044-b42020caca7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T11:30:02.317828Z",
     "start_time": "2024-05-23T11:30:02.305622Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/MF-Police.json', 'r') as f:\n",
    "    policy = json.load(f)\n",
    "\n",
    "print(json.dumps(policy, indent=4)[:1000] + \"\\n...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d7e3fd-a8d4-41fc-a216-5339ae442b0a",
   "metadata": {},
   "source": [
    "Implement function for coverage check\n",
    "\n",
    "1. Find passages from insurance conditions that are most relevant for the given claim\n",
    "2. Ask an LLM whether the claim is covered given the insurance conditions, the policy and the accident description\n",
    "\n",
    "**TASK**: Complete the given code by replacing the placeholder `...` with the actual code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b54ecff-e080-491b-9b26-7d60e81d4d13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T11:30:02.333189Z",
     "start_time": "2024-05-23T11:30:02.319874Z"
    }
   },
   "outputs": [],
   "source": [
    "coverage_check_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Check whether and / or to what extent the given claim as described in the damage description is covered by the insurance.\n",
    "    Policy: '''{policy} '''\n",
    "    General insurance conditions: '''{insurance_conditions} '''\n",
    "    Damage description: '''{damage_description} '''\n",
    "\"\"\")\n",
    "\n",
    "def check_coverage(damage_description, policy=policy, insurance_conditions=insurance_conditions, prompt=coverage_check_prompt, llm=gpt4):\n",
    "    \"\"\"Check if a given claim is covered by the insurance by extracting relevant insurance conditions and calling an LLM\"\"\"\n",
    "    \n",
    "    # Find relevant passages from general insurance conditions\n",
    "    relevant_conditions = ...\n",
    "    \n",
    "    relevant_conditions = \"\\n\\n\".join(relevant_conditions[\"Text\"])\n",
    "\n",
    "    # Build chain and call LLM\n",
    "    chain = prompt | llm\n",
    "    return chain.invoke({\"insurance_conditions\": relevant_conditions, \"policy\": policy, \"damage_description\": damage_description})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4c44a1-0153-4ff9-99dc-bbbcf3a45212",
   "metadata": {},
   "source": [
    "#### Deckung prüfen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da62113-fddf-411e-8604-e5bf014c6629",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:30:03.298735Z",
     "start_time": "2024-05-22T15:29:53.954085Z"
    }
   },
   "outputs": [],
   "source": [
    "check_coverage(\"I had an accident at the Hallauer Bergrennen\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940ec6ea-8b74-48c4-9b3b-aeeff1ac2a6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:30:10.432477Z",
     "start_time": "2024-05-22T15:30:03.301735Z"
    }
   },
   "outputs": [],
   "source": [
    "check_coverage(\n",
    "    \"I was driving on the N1 from Winterthur to St. Gallen when a deer was crossing the street all of a sudden. \"\n",
    "    \"I couldn't stop in time and crashed into the deer.\"\n",
    ").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1242e2dc-68d3-47d5-a5f2-2d5bed8a3e82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:30:27.708454Z",
     "start_time": "2024-05-22T15:30:10.433979Z"
    }
   },
   "outputs": [],
   "source": [
    "check_coverage(\n",
    "    \"I parked my car at the Migros in Rosenberg. When coming back to the car, \"\n",
    "    \"I noticed a dent that obviously had been caused by another car while I was gone.\"\n",
    ").content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e862c9e1-a520-4296-83ac-3047fa031112",
   "metadata": {},
   "source": [
    "**TASK**: Come up with other damage / accident descriptions and check whether they are covered. Adapt the `coverage_check_prompt` to see how it influences the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b47f6a5-8887-4bfe-a77e-0a35edb3fa0d",
   "metadata": {},
   "source": [
    "### Demo 2: Agentic Workflows & ReAct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08b2516-4b39-4c3d-9acd-7a03b51885d8",
   "metadata": {},
   "source": [
    "While the simple approach from above might work in simple cases, it has various limitations:\n",
    "* The semantic search is always executed with the query given by the user. Sometimes this might not find all relevant passages (e.g. for long queries).\n",
    "* The LLM has no information about current information such as the date\n",
    "* LLMs are notoriously bad at maths (although they might think otherwise)\n",
    "\n",
    "One solution is to give the LLM access to external tools such as a calculator and have it decide itself when to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd44b04-8dcf-45c3-a2ce-a4512680fd78",
   "metadata": {},
   "source": [
    "A way to implement this is with **ReAct**. In this approach, the LLM is prompted to think at each step what it needs to do in order to solve a given query. It then can either decide that it has all required information to answer the query or that it has to use another tool at its disposal in order to get additional information:\n",
    "<img src=\"data/react.png\" alt=\"image\" width=\"800\" height=\"auto\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a02a55-bf30-4e7e-9f83-036abfd4bc29",
   "metadata": {},
   "source": [
    "Import required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ade82aa3a449845",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T11:30:04.232954Z",
     "start_time": "2024-05-23T11:30:03.985120Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "\n",
    "from src.utils import Calculator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65af0650-04e8-42e4-b998-eec9f96c77c6",
   "metadata": {},
   "source": [
    "Define the available tools as python functions. The docstrings are made available to the LLM and should therefore be as descriptive as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ff042f82b3166b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T11:32:11.076538Z",
     "start_time": "2024-05-23T11:32:11.053176Z"
    }
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_current_date() -> str:\n",
    "    \"\"\"\n",
    "    Get the current date. Always use this tool when dates are relevant to answer the query.\n",
    "    \"\"\"\n",
    "    return date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_relevant_terms_and_conditions(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Get the relevant terms and conditions for a given query by doing a semantic search.\n",
    "    Use this tool multiple times with different queries if you are missing relevant information.\n",
    "    \"\"\"\n",
    "    return semantic_search(query, insurance_conditions)[\"Text\"]\n",
    "\n",
    "\n",
    "@tool\n",
    "def make_calculation(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Make a calculation by solving the given mathematical expression.\n",
    "    Always use this tool when making calculations. Don't try to make calculations without it.\n",
    "    \"\"\"\n",
    "    # Make sure the expression is well formatted\n",
    "    expression = expression.replace(\"'\", \"\").replace('\"', '').strip()\n",
    "    \n",
    "    calc = Calculator()\n",
    "    return calc.eval_expr(expression)\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_current_car_value(model: str) -> int:\n",
    "    \"\"\"Get the value of the specified car model in CHF\"\"\"\n",
    "    return 40000  # Dummy value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84478cbc-babe-4553-b83a-01862f8592be",
   "metadata": {},
   "source": [
    "Define the *ReAct* Prompt. This is just a template and can be adapted if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5360f3907bfa9074",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T11:32:12.333779Z",
     "start_time": "2024-05-23T11:32:12.317562Z"
    }
   },
   "outputs": [],
   "source": [
    "react_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "    \n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "\n",
    "Thought: you should always think about what to do\n",
    "\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "\n",
    "Action Input: the input to the action\n",
    "\n",
    "Observation: the result of the action\n",
    "\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "\n",
    "Thought: I now know the final answer\n",
    "\n",
    "Final Answer: the final answer to the original input question in the language of the question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: Check whether and / or to what extent the given claim as described in the damage description is covered by the insurance. Policy: '''{policy} ''' Damage description: '''{damage_description} '''\n",
    "\n",
    "Thought:{agent_scratchpad}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2953bac2-c40a-4154-bcb2-8dbbcaaa5011",
   "metadata": {},
   "source": [
    "Initialize the ReAct agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2e60c5a2dd5b5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T11:32:12.533457Z",
     "start_time": "2024-05-23T11:32:12.521996Z"
    }
   },
   "outputs": [],
   "source": [
    "tools = [get_current_date, get_relevant_terms_and_conditions, make_calculation, get_current_car_value]\n",
    "\n",
    "agent = create_react_agent(gpt4, tools, react_prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464122b8-46c5-49f0-ba15-3f663bd87b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def react_coverage_check(damage_description):\n",
    "    return agent_executor.invoke({\"policy\": policy, \"damage_description\": damage_description})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b6061b-7eda-44c4-9097-6feaf50c079e",
   "metadata": {},
   "source": [
    "Now we are going to execute the coverage check with *ReAct*. Whether the given damage is considered a total loss, i.e. whether the covers the replacement of the car or only the repair, depends on several aspects:\n",
    "* How old is the car?\n",
    "* What would repairing the car cost in comparison to the value of the car?\n",
    "* Does the policy include a \"purchase price guarantee\".\n",
    "\n",
    "See section C10.2 in the [insurance conditions](data/MF-GIC.pdf) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4647b6196d915dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T11:32:13.260783Z",
     "start_time": "2024-05-23T11:32:13.246552Z"
    }
   },
   "outputs": [],
   "source": [
    "react_coverage_check(\n",
    "    \"I crashed into a tree with my Tesla last week while driving to work. The repair cost estimate is 25000 CHF. \"\n",
    "    \"Is this considered a total loss? In other words, will my insurance cover the costs to replace the car or only pay for the repair?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18ca7fa-188c-42ed-8dbc-bfd8d841aabd",
   "metadata": {},
   "source": [
    "**TASKs**: \n",
    "* Execute the same coverage check multiple times to see what happens\n",
    "* Adapt the prompt to see if you can find a way to make the agent reason in a correct way.\n",
    "* Come up with additional claims to see how it changes the behaviour of the agent\n",
    "* Change the LLM from `gpt4` to `gpt35` to see how it influences the behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d647f98-08a4-4784-9675-f32a3c910d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
